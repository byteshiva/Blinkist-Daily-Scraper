![Moral Tribes](https://images.blinkist.com/images/books/5c6a7a256cee0700079ef289/1_1/470.jpg)
# Moral Tribes
*Joshua Greene*

>Moral Tribes (2013) shows how humans have learned to make moral decisions. Humans once lived as close-knit tribes but have now formed more complex societies. We debate everything from abortion laws to global warming and wonder if we’ll ever agree on solutions. These blinks show us how best to make moral decisions that will benefit everyone.


# What’s in it for me? Learn how to make better decisions by putting your own morality into context.

Every which way you look, there’s a hot button topic flaring up. Politics has ceased to be about considered debate as opponents polarize themselves, convinced that each has the moral upper hand.

But it could be different. The way we argue about our moral status is down to humanity’s evolutionary history. All it takes is a bit of effort and awareness, and soon different sides can come to conclusions that will ultimately benefit society and ensure everyone’s happiness.

In the following blinks, you’ll learn what barriers prevent us from reaching mutual understandings and what can be done to overcome that trend.

In these blinks, you’ll learn

- why clashes of commonsense morality are so challenging to resolve;

- what the prisoner’s dilemma is; and

- why cake is more appealing when your brain is busy.


# Cooperation between groups is often undermined by self-interest or a group’s own sense of morality.

The world is changing rapidly, but humans are still biologically much the same. Evolution has given us the skills to cooperate *within* groups, but unfortunately, our ability to cooperate *between* groups still leaves much to be desired. The history of conflict is enough to tell us that.

Mutually beneficial cooperation is endangered by many things, but the clearest threat is what’s known as *the tragedy of the commons.*

This is fancy sociology speak for the conflict between self-interest and collective interest: in other words, *Me Versus Us/ You.*

Imagine that Art is journeying alone through the Wild West. He spots the silhouette of another traveler up ahead at a watering hole. Art isn’t sure whether the stranger is armed, but Art does have his pistols with him. They meet and size each other up as their horses drink at the watering hole.

If Art thinks selfishly, there’s little to be lost if he shoots Bud, the stranger. There’d be no chance of Art getting robbed, for starters. But let’s say that Art opts not to shoot Bud, for now. When Art later nods off, Bud spikes his whiskey with poison. Bud, you see, is also afraid of being robbed. When Art wakes, he changes his mind and shoots Bud dead. Then he unwittingly knocks back the poisoned whiskey and dies. If Art and Bud had been less self-interested and instead acted cooperatively, neither would have died. That’s the tragedy of the commons.

A second threat to mutually beneficial cooperation is known as *the tragedy of commonsense morality. *This time it’s a question of* Us Versus Them*. In other words, one group sets its own values against those of another.

An excellent example of this mentality is demonstrated by the story of the Danish political newspaper *Jyllands-Posten*. In response to the Islamic hadith forbidding visual depictions of the Prophet Muhammad, it published a series of cartoons satirizing Muhammad in 2005. The general climate was also important: there was an ongoing debate about journalists self-censoring their views on Islam.

Global media outlets followed the controversy. Before long, violent protests sprang up around the Muslim world. Over a hundred people were killed, and Danish embassies in Syria, Lebanon and Iran were set on fire.

The two groups – Danish journalists and Muslims – were each fighting for what they saw as commonsense morality. The journalists hated feeling censored, while Muslims didn’t want their religion disrespected. But the end result was conflict. This is how commonsense morality can lead to tragedy.

# The prisoner’s dilemma gives us an insight into the functioning of moral principles.

A famous thought experiment is often cited when questions of morality arise. It’s called *the prisoner’s dilemma*. To explain it we’ll have to return to our friends Art and Bud.

This time, Art and Bud have teamed up and started robbing banks together. Eventually, the sheriff arrests them, but he doesn’t have enough evidence to pin the crime on the pair. To get solid convictions, the sheriff needs to wheedle a confession out of them. So the heisters are split up and given a moral puzzle: if Art confesses but Bud doesn’t, then Art receives a one-year sentence and Bud gets ten, and vice versa. However, if they both confess, they each get an eight-year sentence. And if they keep quiet? Well, that’s two years each.

This begs the question: which moral principles dictate Art and Bud’s decision-making?

First off, their choices are probably affected by their relationship to one another.

If Art and Bud were brothers, they’d be significantly less inclined to confess and so betray their sibling.

Equally, if they thought that they could have a successful future partnership as bank robbers, staying quiet would certainly do them both good.

However, if the pair of strangers didn’t care about each other, they’d be much more likely to confess. After all, that way they’d each receive a one-year or an eight-year sentence instead of a two-year or a ten-year one.

No matter what the other does, the end result for either is better if they choose to confess. That means the most likely outcome is that they’d get eight years each.

There’s another factor that might affect the decision-making process: possible future repercussions.

For instance, Art could threaten Bud with murder if he dares to confess. However, intimidation isn’t always the best strategy. In this case, Art would have to wait ten years before he could get his hands on Bud. And besides, murder is a risky business.

Now imagine the two are part of a cartel, the League of Tight-Lipped Bank Robbers. Each member swears to keep to a strict code of silence. He who fails to cooperate must face violent repercussions from the others. In this case, Art and Bud won’t be singing any time soon.

# 

*“Cooperation is why we’re here, and yet, at the same time, maintaining cooperation is our greatest challenge.”*

# Utilitarianism recognizes that each of us deserves equal happiness but undervalues people’s rights in the process.

Ask yourself, why did you go to work today? Most likely for your paycheck. And why do you need the money? For food. And the food? Well, it’s because you want to keep living. And why live? So you can spend your time with friends and family, and be happy. No matter what the precise sequence is, you’re going to realize that what matters, in the end, is happiness.

This is where* utilitarianism* can be your guide. The philosophy holds that the most important concern when making moral decisions is happiness.

To better understand this, let’s look at another famous thought experiment, *the* *footbridge* *dilemma.*

Imagine that a train carriage is hurtling out of control toward five railway workers. If struck, they will be killed. You are standing on a footbridge overlooking the tracks. Next to you is another man carrying a large backpack. You realize the only way to save the five workers it to hurl this heavily loaded man onto the tracks below. This would kill him instantaneously but also stop the carriage and save the workers. So is pushing the man off the bridge morally acceptable?

Well, according to the principles of utilitarianism, you’re going to have to give him a shove. As each life is equal, this will ensure the greater happiness of the five at the cost of one life.

It’s easy to see the problem with utilitarianism when we roleplay the footbridge dilemma: it clearly doesn’t value individual rights at all highly.

That’s because utilitarians think it’s fine to overlook an individual’s happiness if the end result is greater overall happiness.

Here’s another example: imagine you live in a society where a minority of the populace is enslaved. If the majority are happy with this state of affairs, their overall happiness totals more that of the enslaved minority. That’s fine as far as utilitarianism is concerned, but extremely morally dubious.

Slavery generates riches for some, but incredible anguish for others. When we look at the positives and negatives, it’s clear that the moral negatives shouldn’t be ignored. You can’t just weigh one against the other.

If we use utilitarianism to make moral decisions, we shouldn’t forget the inalienable rights of individuals in the process. These rights should not be dismissed just because the happiness of a majority group is quantifiably larger.

# 

*“Human empathy is fickle and limited, but our capacity for empathy may provide an emotional seed that, when watered by reasoning, flowers into the ideal of impartial morality.”*

# Moral thinking comes in two modes: automatic or manual.

The modern camera is a wonder of technology. A photographer can choose the automatic point-and-shoot mode or else use the manual setting, exerting greater control over the outcome. It’s a nice analogy for moral thinking, where we also have two modes: *automatic* and *manual*.

The researchers Baba Shiv and Alexander Fedorikhin proved this in an experiment in 1999. In their study, the participants were told to memorize a number, walk down a hallway and tell a tester the number.

Half of the participants were given a two-digit number to memorize, the other half a seven-digit number. Clearly, the second group had the greater cognitive task.

In the hallway, subjects were instructed to take one of two snack options, either a healthy piece of fruit or a slice of rich chocolate cake.

It turned out that those under a higher cognitive load were 50 percent more likely to opt for the chocolate cake.

This happened because they were in *automatic mode*. In other words, they were guided by intuition and emotion.

Our automatic mode only cares for what we can get in the moment. In this case, the rich charms of cake were hard to resist. The automatic mode is built up from our accumulated responses shaped by genes, cultural experiences, as well as trial and error.

*Manual mode*, however, works differently. In it, reasoning and thinking play a key role.

The controlled manual mode mulls over short- and long-term benefits. So in Shiv and Fedorikhin’s experiment, it reminded participants with lower cognitive loads that the fruit was better for them.

The general lesson here is clear: automatic thinking leads to more errors but allows for easier decision-making, without overloading the conscious mind. Equally, as we saw with the participants who had to remember seven digits, the automatic mode is a fallback option when the manual mode is busy.

# Who we help depends on how personal our connection to them feels.

Imagine you’re walking in a park, dressed up in very expensive $500 clothing. You see a child drowning in a pond. Theoretically, it’d be easy enough to save the child’s life by diving in yourself, but you’d destroy your clothes in the process. Of course, that’s no real dilemma at all: you’d choose the child over your clothes every time.

The real question is, why is it morally acceptable to spend so much on a suit in the first place. Just think – that money could have been used by a charity for all sorts of things, saving many more children.

Much the same dynamic exists for empathy. It turns out that the strength of empathy is determined by two factors: physical distance and personal connection.

The author and his colleague Jay Musen conducted an experiment to investigate this relationship more fully. Participants were instructed to envisage two scenarios.

In the first, subjects were asked to imagine vacationing in a country and experiencing a catastrophic typhoon. In the second, the subjects visualized having a friend there who gave them a live audio-visual feed of the aftermath. Of those who projected themselves as being physically on the scene, 68 percent said they were morally obliged to help, compared with just 34 percent of the live-feed group.

The same phenomenon can be witnessed in real-world scenarios. For example, in 1987, an 18-month-old girl fell down a well in Texas. She was trapped there for almost 60 hours. In support of the rescue effort, her family received more than $700,000 from strangers. Happily, the toddler was rescued by emergency services.

But what’s interesting is that the donated money could have saved the lives of thousands dying in developing countries. So why was it given for this cause only?

We feel a responsibility to help due to our feelings of anxiety and guilt but only if we feel a connection to the case. The girl down the well felt personal, even to faraway strangers.

When our ties to the event are weaker, we feel less compelled to act because we feel more distance, even if the disaster is larger in scale.

# Beliefs and values tend to be justified by rights and duties, but a pragmatic approach is more illuminating.

One of the most contentious debates boiling in the world today revolves around abortion.

Generally speaking, pro-choice advocates and pro-lifers justify their points of view by looking at *rights* and *duties*.

Pro-choicers view abortion as a facet of women’s *rights *– of course they should be able to make decisions about their bodies.

Equally, pro-lifers claim to oppose abortion due to their *duty* to protect all life.

These two arguments are therefore grounded in two completely different concepts. As a result, the only common ground they can debate is the question of when life actually begins.

Pro-life arguments focus on the potential of the human life that abortion terminates. For most pro-lifers, it’s a *person’s* life that begins at conception, the moment sperm and egg merge.

Pro-choicers, on the other hand, don’t believe life begins at conception, but rather when a fetus has basic consciousness, meaning they have an awareness of their body and can feel pain. But focusing on when life begins does not actually answer the question of why exactly is or isn't early-term abortion *morally *justified?

In this case, utilitarianism can offer a pragmatic way to approach the debate.

Instead of worrying about when life begins, we should pose moral questions. For instance, would banning abortion impact society as a whole positively or negatively?

If abortions were outlawed, what would happen? Perhaps people would alter their sexual behavior, despite it being a satisfying part of life. Furthermore, some women might seek illegal abortions or go abroad for them, which could be dangerous. And finally, some women might give birth to babies whom they’re not in a position to care for properly, either emotionally or financially.

Meanwhile, without abortions, more babies would be born. They could also experience happiness, thereby technically increasing overall happiness in the world. But then, by the same measure, should we not ban contraceptives and abstinence too, which also prevent babies from being born? In fact, would the moral imperative for adults be to pump out as many happy babies as possible? This seems like too harsh a demand.

One could also argue that the possibility of having abortions leads to an increase in harmful sex, for instance, between teenagers who are not yet ready for it. But it’s not clear if banning abortions would actually reduce the amount of harmful sex, because presumably teenagers who are more mature and mindful of their choices are also the most likely to be sexually active.

Based on this reasoning, it seems that pro-choicers would have much stronger grounds for their perspective, as the possibility of legal abortion maximizes society’s happiness at large.

Major debates like there continuously swirl around us, whether they’re over abortion, laws, taxes, healthcare, capital punishment, marriage equality, gun control or immigration policies. A better understanding of moral psychology can help us make progress even in these challenging debates.

# Final summary

The key message in these blinks:

**Humanity’s sense of morality is built on evolution and cultural experiences. We often respond to situations around us automatically, without really thinking them through. But when it comes to moral dilemmas, this won’t lead to the best result. Prioritizing our own interests often leads to poorer outcomes than cooperating would and also results in the tragedy of the commons. This is why careful moral reasoning is necessary, especially when it comes to contentious, impactful topics.**

Actionable advice:

**Confront your ignorance and encourage others to do the same.**

Controversial real-world moral problems, such as global warming and the healthcare system, are very complex. Despite that, people often maintain strong opinions on these subjects even when they don’t grasp the fundamentals. Maybe you’re one of them? Force yourself to justify why you disagree with a specific policy, and, if you struggle, accept your ignorance on the matter. You may even find yourself being more receptive to others’ views as a result.

**Got feedback?**

We’d sure love to hear what you think about our content! Just drop an email to remember@blinkist.com with the title of this book as the subject line and share your thoughts!

**What to read next:*****Us vs. Them*****, by Ian Bremmer**

In the blinks you’ve just read, you learned that we can’t resist depicting ourselves (Us) fighting against a group with which we share nothing in common (Them). You also learned how we can overcome those issues and make better moral decisions for society at large.

But Ian Bremmer’s *Us vs. Them* (2018) shows us how in the United States, China, Venezuela, Turkey and many other countries, unhappy citizens are being won over by populist politicians promising easy answers. *Us vs. Them* demonstrates not just the contexts for this trend, but also what can be done to face down these deceptive populists in the future.


Source: [Moral Tribes by Joshua Greene](https://www.blinkist.com/en/nc/daily/reader/moral-tribes-en)